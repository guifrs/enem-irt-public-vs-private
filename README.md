# Causal Inference in ENEM 2017

_Exploring how public vs. private high schools shape student performance under Item Response Theory_

[![Python](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

This project investigates whether attending a public high school causally affects ENEM 2017 performance, controlling for ability, socioeconomic status, demographics, and exam characteristics.

ENEM uses Item Response Theory (IRT) â€” meaning two students with the same number of correct answers can receive different final scores depending on the pattern of responses.

This unique scoring rule makes ENEM a rich environment for applied causal inference.

## ğŸ¯ Motivation

While exploring the microdata, I plotted the relationship between number of correct answers and final IRT-adjusted score using the script `03_plot_hits.py`.

![alt text](image-1.png)

One surprising pattern emerged:

> Students with the same number of correct answers often receive drastically different scores â€” sometimes 150+ points apart.

This opened two key questions:

**1. What explains this score variation?**

    If students guess or show inconsistent patterns across items, IRT penalizes them.


**2. Is there a systematic disadvantage for public-school students?**

  A hypothesis emerges:

>    Students from public schools may have experienced larger learning gaps during high school, producing answer patterns that IRT interprets as lower â€œabilityâ€, even when achieving the same number of correct answers.

This repository explores this hypothesis rigorously.

## ğŸ“Š Regression Results â€” What We Learn

One of the core outputs is the regression table for Mathematics.
Below is a simplified version of the model progression:

|                         | (1)                 | (2)                 | (3)                 | (4)                 | (5)                 |
|-------------------------|---------------------|---------------------|---------------------|---------------------|---------------------|
| **Constant**            | 589.00*** (0.10)    | 305.13*** (0.09)    | 305.21*** (0.10)    | 293.08*** (0.15)    | 300.75*** (0.22)    |
| **Public School**       | -89.08*** (0.11)    | -14.14*** (0.06)    | -14.16*** (0.06)    | -7.99*** (0.06)     | -7.93*** (0.06)     |
| **Number of Correct Answers** |                     | 19.06*** (0.01)    | 19.05*** (0.01)    | 18.67*** (0.01)     | 18.51*** (0.01)     |
| **Exam Code Controls**  |                     |                     | Yes                 | Yes                 | Yes                 |
| **Income Controls**     |                     |                     |                     | Yes                 | Yes                 |
| **Sex Control**         |                     |                     |                     |                     | Yes                 |
| **Race Controls**       |                     |                     |                     |                     | Yes                 |
| **RÂ²**                  | 0.12                | 0.79                | 0.79                | 0.80                | 0.80                |
| **N**                   | 4,423,760           | 4,423,760           | 4,423,760           | 4,423,760           | 4,423,760           |


### ğŸ” Interpretation

**Model (1): Raw difference**

Public-school students score 89 points lower, on average.
But this is a naÃ¯ve comparison: it ignores differences in ability, income, or background.

**Model (2): Controlling for number of correct answers**

Once we adjust for the actual knowledge demonstrated, the gap shrinks to 14 points.
This means:

> Even when answering the same number of items correctly, public-school students still receive lower IRT scores.

**Models (3)â€“(5): Adding exam code, income, sex, and race controls**

After fully controlling for background and exam characteristics, the gap drops to ~8 points.
This residual difference is consistent with the hypothesis:

> Public-school students may produce answer patterns that IRT interprets as lower latent ability (guessing or inconsistent response behavior).

RÂ² â‰ˆ 0.80
Models explain 80% of variation â€” unusually high for microdata, thanks to the strong predictive power of number of correct answers.

## ğŸ› ï¸ Technologies & Performance Considerations

Throughout the project, I intentionally used different libraries to understand their performance and ergonomics when handling millions of rows:

### Polars

Used for downloading, cleaning, and converting the raw CSV (~4 GB) into an optimized Parquet file.

â†’ Extremely fast and memory-efficient.

### DuckDB

Used in `02_build_hits.py` to generate item-level expansions and compute the number of correct answers.

â†’ Perfect for large aggregations without loading everything into RAM.

### Pandas & Matplotlib

Used for analysis and visualization (`03_plot_hits.py`).

â†’ Best suited for plotting workflows and exploratory analysis.

### Statsmodels

Used for all regression models (`04_regressions.py`).

â†’ Clear API for OLS, easy to export results to tables.

This modular pipeline mirrors real data-engineering workflows and showcases how each tool excels in its niche.

## ğŸ“ Project Structure

```
enem-irt-public-vs-private/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Downloaded microdata (not versioned)
â”‚   â””â”€â”€ processed/                # Cleaned Parquet + hits dataset
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_download_and_clean.py  # Polars ETL
â”‚   â”œâ”€â”€ 02_build_hits.py          # DuckDB item expansions
â”‚   â”œâ”€â”€ 03_plot_hits.py           # Exploratory plots
â”‚   â””â”€â”€ 04_regressions.py         # Statsmodels regressions
â”‚
â”œâ”€â”€ figures/                      # All generated plots
â”œâ”€â”€ tables/regressions/           # Regression tables (CSV)
â”‚
â”œâ”€â”€ thesis_PT_BR.pdf              # Full thesis, in Portuguese
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ uv.lock
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

## ğŸš€ How to Run the Project

1. Clone the repository

```
git clone https://github.com/guifrs/enem-irt-public-vs-private.git
cd enem-irt-public-vs-private
```

2. Install dependencies using uv

```
uv venv .venv
source .venv/bin/activate      # Windows: .venv\Scripts\activate
uv sync
```

3. Run the pipeline scripts in order

```
uv run notebooks/01_download_and_clean.py
uv run notebooks/02_build_hits.py
uv run notebooks/03_plot_hits.py
uv run notebooks/04_regressions.py
```

## ğŸ“„ Full Thesis (Portuguese)

The full academic version of this study â€” including additional models, theoretical background, and robustness checks â€” is available in the repository:

â¡ï¸ thesis_PT_BR.pdf

## ğŸ“¬ Contact

Feel free to open issues or reach out for collaboration, suggestions, or research discussions.